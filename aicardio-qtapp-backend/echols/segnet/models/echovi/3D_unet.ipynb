{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "from monai.transforms import \\\n",
    "    Compose, LoadNiftid, AddChanneld, ScaleIntensityRanged, CropForegroundd, \\\n",
    "    RandCropByPosNegLabeld, RandAffined, Spacingd, Orientationd, ToTensord\n",
    "from monai.data import list_data_collate, sliding_window_inference\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.nets import Unet\n",
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting monai\n",
      "  Using cached monai-0.1.0-202004191421-py3-none-any.whl (121 kB)\n",
      "Collecting nibabel\n",
      "  Using cached nibabel-3.1.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: tensorboard in /data.local/giangh/envs/pipeline/lib/python3.7/site-packages (from monai) (2.1.0)\n",
      "Requirement already satisfied: numpy in /data.local/giangh/envs/pipeline/lib/python3.7/site-packages (from monai) (1.18.2)\n",
      "Requirement already satisfied: pillow in /data.local/giangh/envs/pipeline/lib/python3.7/site-packages (from monai) (6.1.0)\n",
      "Requirement already satisfied: scikit-image in /data.local/giangh/envs/pipeline/lib/python3.7/site-packages (from monai) (0.16.2)\n",
      "Requirement already satisfied: scipy in /data.local/giangh/envs/pipeline/lib/python3.7/site-packages (from monai) (1.4.1)\n",
      "Collecting torch>=1.4\n",
      "  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n",
      "\u001b[K     |█████████▊                      | 227.2 MB 5.5 MB/s eta 0:01:36"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "from albumentations import (\n",
    "    CLAHE, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, OneOf, Compose, Normalize,\n",
    ")\n",
    "\n",
    "def strong_aug(p=0.5):\n",
    "    return Compose([\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.4),\n",
    "        OneOf([\n",
    "            MotionBlur(p=0.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=5, p=0.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=0.6),\n",
    "        ], p=1),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomBrightnessContrast(),\n",
    "        ], p=0.3),\n",
    "        HueSaturationValue(p=0.3),\n",
    "    ], p=p)\n",
    "\n",
    "\n",
    "AUGMENTATION = strong_aug(p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "def get_index(path):\n",
    "    file_name = os.path.basename(path)[:-4]\n",
    "    index = file_name.rsplit('_', 1)[1]\n",
    "    return int(index)\n",
    "\n",
    "class EchoDataset(data.Dataset):\n",
    "    # for multi object, do shuffling\n",
    "\n",
    "    def __init__(self, root, is_train = True, transforms=None, num_frame_interval=32, single_object=True, target_size=(256, 256)):\n",
    "        self.root = root\n",
    "        self.mask_dir = os.path.join(root, 'masks')\n",
    "        self.image_dir = os.path.join(root, 'images')\n",
    "\n",
    "        self.num_frames = {}\n",
    "        self.num_objects = {}\n",
    "        self.shape = {}\n",
    "        self.num_frame_interval = num_frame_interval\n",
    "        self.video_data = defaultdict(list)\n",
    "        self.__get_video_name(self.image_dir)\n",
    "        self.list_video = list(self.video_data.keys())\n",
    "        self.list_random_seed = [random.randint(0,9999) for i in range(len(self.list_video))]\n",
    "        self.do_augment = is_train\n",
    "        self.target_shape = target_size\n",
    "        self.transforms = transforms\n",
    "        self.K = 2\n",
    "        \n",
    "    def To_onehot(self, mask):\n",
    "        M = np.zeros((self.K, mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
    "        for k in range(self.K):\n",
    "            M[k] = (mask == k).astype(np.uint8)\n",
    "        return M\n",
    "    \n",
    "    def __get_video_name(self, root_dir):\n",
    "        for f in glob.glob(os.path.join(root_dir, \"**.jpg\")):\n",
    "            filename = os.path.basename(f)\n",
    "            video_name = filename.rsplit('_', 1)[0]\n",
    "            self.video_data[video_name].append(f)\n",
    "        split_video_data = defaultdict(list)\n",
    "        for k in self.video_data.keys():\n",
    "            frames = self.video_data[k]\n",
    "            frames = sorted(frames, key=get_index)\n",
    "            frames = list( dict.fromkeys(frames) )\n",
    "            n_time = len(frames) // self.num_frame_interval\n",
    "            if n_time == 0:\n",
    "                frames = np.resize(frames, self.num_frame_interval)\n",
    "                split_video_data[str(k) + f\"_part_{i}\"] = frames\n",
    "            else:\n",
    "                for i in range(n_time):\n",
    "                    split_video_data[str(k) + f\"_part_{i}\"] = \\\n",
    "                        frames[i * self.num_frame_interval:(i + 1) * self.num_frame_interval]\n",
    "        self.video_data = split_video_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_video)\n",
    "    \n",
    "    def add_background(self,mask):\n",
    "        h,w = mask.shape\n",
    "        new_mask = np.zeros((h,w,2))\n",
    "        new_mask[:,:,1] = mask\n",
    "        new_mask[:,:,0] = 1-mask\n",
    "        return new_mask\n",
    "    \n",
    "    def _augment(self,image, mask, seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        if np.count_nonzero(mask) == 0:\n",
    "            return AUGMENTATION(image=image)['image'], mask\n",
    "        else:\n",
    "            augmented = AUGMENTATION(image=image, mask=mask)\n",
    "            return augmented['image'],augmented['mask']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        video = self.video_data[self.list_video[index]]\n",
    "        info = {}\n",
    "        info['name'] = video\n",
    "        correct_masks = []\n",
    "        list_image = []\n",
    "        list_mask = []\n",
    "        t = 1000 * time.time() # current time in milliseconds\n",
    "        seed = int(t) % 2**32\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        for frame_idx in range(len(video)):\n",
    "            img_file = video[frame_idx]\n",
    "            frame = cv2.imread(img_file)\n",
    "            frame = cv2.resize(frame, self.target_shape)\n",
    "            h,w = frame.shape[:2]\n",
    "            try:\n",
    "                file_name = os.path.basename(img_file)[:-4]\n",
    "                mask_file = os.path.join(self.mask_dir, file_name + '.png')\n",
    "                mask = np.uint8(cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE) / 255.0)\n",
    "                mask = cv2.resize(mask, self.target_shape, cv2.INTER_NEAREST)\n",
    "                correct_masks.append(1)\n",
    "            except:\n",
    "                correct_masks.append(0)\n",
    "                mask = np.zeros((h,w))\n",
    "            if self.do_augment:\n",
    "                frame,mask = self._augment(frame,mask,seed)\n",
    "            mask = self.add_background(mask)\n",
    "            frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)[...,None]\n",
    "            list_image.append(frame)\n",
    "            list_mask.append(mask)\n",
    "        images = np.array(list_image)\n",
    "        masks = np.array(list_mask)\n",
    "        images = np.transpose(images,(3,0,1,2))\n",
    "        masks = np.transpose(masks,(3,0,1,2)) \n",
    "        # transpose from (t, H, W, C) to (t, C, H, W)\n",
    "        images = torch.from_numpy(images).float()\n",
    "        N_masks = (masks > 0.5).astype(np.uint8) * (masks < 255).astype(np.uint8)\n",
    "        Ms = torch.from_numpy(N_masks).float()\n",
    "        correct_masks = torch.from_numpy(np.array(correct_masks)).bool()\n",
    "    \n",
    "        return dict(\n",
    "            image=images,\n",
    "            label=Ms.to(dtype=torch.uint8),\n",
    "            correct_masks=correct_masks,\n",
    "            video_data=str(self.list_video[index])\n",
    "        )\n",
    "    \n",
    "    def All_to_onehot(self, masks):\n",
    "        # num_objects as channel\n",
    "        Ms = np.zeros((masks.shape[0], self.K, masks.shape[1], masks.shape[2]), dtype=np.uint8)\n",
    "        for n in range(masks.shape[0]):\n",
    "            Ms[n] = self.To_onehot(masks[n])\n",
    "        return Ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EchoDataset(\"/data.local/phinv/video_segmentation/data/2019-12-04_2C/train_dev/\",is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(1)['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_ds = dataset\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "image, label = (check_data['image'][0][0], check_data['label'][0][1])\n",
    "print('image shape: {}, label shape: {}'.format(image.shape, label.shape))\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure('check', (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('image')\n",
    "plt.imshow(image[0,:, :], cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('label')\n",
    "plt.imshow(label[0,:, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_data_collate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1ab15a1cfa95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# use batch_size=2 to load images and use RandCropByPosNegLabeld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# to generate 2 x 4 images for network training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_data_collate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEchoDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data.local/phinv/video_segmentation/data/2019-12-04_2C/test/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_data_collate' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds = EchoDataset(\"/data.local/phinv/video_segmentation/data/2019-12-04_2C/train_dev/\",is_train=True)\n",
    "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4, collate_fn=list_data_collate)\n",
    "\n",
    "val_ds = EchoDataset(\"/data.local/phinv/video_segmentation/data/2019-12-04_2C/test/\",is_train=False)\n",
    "# val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softIoU(y_pred, y_true, is_masks):\n",
    "    y_pred = y_pred.contiguous()\n",
    "    y_true = y_true.contiguous()\n",
    "    B,C,T,H,W = y_pred.shape\n",
    "    y_pred = y_pred.permute(0,2,1,3,4)\n",
    "    y_true = y_true.permute(0,2,1,3,4)\n",
    "    y_pred = y_pred.reshape(B,T,-1)\n",
    "    y_true = y_true.reshape(B,T,-1)\n",
    "    intersection = (y_true * y_pred).sum(dim=-1)\n",
    "    union = y_true.sum(dim=-1) + y_pred.sum(dim=-1) - intersection\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    loss = 1.0 - iou\n",
    "    loss = loss[is_masks]\n",
    "    loss = torch.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def segmentation_metrics(ypreds, ytrues,is_masks):\n",
    "    eps = 1e-6\n",
    "    ypreds = ypreds.contiguous()\n",
    "    ytrues = ytrues.contiguous()\n",
    "    B,C,T,H,W = ytrues.shape\n",
    "    ypreds = torch.argmax(ypreds,dim=1)\n",
    "    ytrues = torch.argmax(ytrues,dim=1)\n",
    "    ious = []\n",
    "    dices = []\n",
    "    for batch_idx in range(B):\n",
    "        for frame_idx in range(T):\n",
    "            if is_masks[batch_idx,frame_idx]:\n",
    "                ypred = ypreds[batch_idx,frame_idx]\n",
    "                ytrue = ytrues[batch_idx,frame_idx]\n",
    "                with torch.no_grad():\n",
    "                    intersection = torch.sum(ypred*ytrue)\n",
    "                    union = torch.sum(ypred)+torch.sum(ytrue)\n",
    "                    iou = (intersection+eps)/(union-intersection+eps)\n",
    "                    dice = (2*intersection+eps)/(union+eps)\n",
    "                    ious.append(iou.item())\n",
    "                    dices.append(dice.item())\n",
    "        \n",
    "    return np.mean(ious), np.mean(dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EchoVi import EchoViNet\n",
    "## # standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device('cuda:1')\n",
    "# device = torch.device('cpu')\n",
    "32, 64, 256, 512, 1024\n",
    "# model = Unet(dimensions=3, in_channels=1, out_channels=2, channels=(64, 128, 256, 512, 1024),\n",
    "#                                  strides=(2, 2, 2, 2), num_res_units=2, norm=Norm.BATCH).to(device)\n",
    "model = EchoViNet(n_class=2).to(device)\n",
    "#  channels=(16, 32, 64, 128, 256)\n",
    "loss_function = softIoU\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data.local/phinv/envs/echo/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/298, train_loss: 5.1439 iou: 0.0432 dice: 0.0826\n",
      "11/298, train_loss: 4.2378 iou: 0.1756 dice: 0.2970\n",
      "21/298, train_loss: 5.3722 iou: 0.3751 dice: 0.5448\n",
      "31/298, train_loss: 2.0729 iou: 0.4791 dice: 0.6472\n",
      "41/298, train_loss: 1.4889 iou: 0.4882 dice: 0.6553\n",
      "51/298, train_loss: 1.0874 iou: 0.5098 dice: 0.6747\n",
      "61/298, train_loss: 0.8288 iou: 0.6170 dice: 0.7625\n",
      "71/298, train_loss: 0.8699 iou: 0.6081 dice: 0.7551\n",
      "81/298, train_loss: 0.5724 iou: 0.3763 dice: 0.5461\n",
      "91/298, train_loss: 0.4486 iou: 0.6850 dice: 0.8128\n",
      "101/298, train_loss: 0.9569 iou: 0.4872 dice: 0.6546\n",
      "111/298, train_loss: 0.7750 iou: 0.5352 dice: 0.6964\n",
      "121/298, train_loss: 1.5759 iou: 0.3959 dice: 0.5662\n",
      "131/298, train_loss: 0.2997 iou: 0.6362 dice: 0.7767\n",
      "141/298, train_loss: 1.0568 iou: 0.2307 dice: 0.3727\n",
      "151/298, train_loss: 1.8261 iou: 0.2822 dice: 0.4392\n",
      "161/298, train_loss: 0.7864 iou: 0.7321 dice: 0.8446\n",
      "171/298, train_loss: 0.2299 iou: 0.7721 dice: 0.8703\n",
      "181/298, train_loss: 0.3852 iou: 0.6728 dice: 0.8025\n",
      "191/298, train_loss: 0.8123 iou: 0.6210 dice: 0.7634\n",
      "201/298, train_loss: 0.3218 iou: 0.7627 dice: 0.8651\n",
      "211/298, train_loss: 1.4771 iou: 0.4658 dice: 0.6354\n",
      "221/298, train_loss: 0.4047 iou: 0.7718 dice: 0.8686\n",
      "231/298, train_loss: 0.3294 iou: 0.6366 dice: 0.7776\n",
      "241/298, train_loss: 0.2654 iou: 0.7530 dice: 0.8571\n",
      "251/298, train_loss: 0.2427 iou: 0.7948 dice: 0.8852\n",
      "261/298, train_loss: 0.5669 iou: 0.5463 dice: 0.7058\n",
      "271/298, train_loss: 0.5441 iou: 0.6445 dice: 0.7830\n",
      "281/298, train_loss: 0.2046 iou: 0.6866 dice: 0.8123\n",
      "291/298, train_loss: 0.3069 iou: 0.7713 dice: 0.8699\n",
      "epoch 1 average loss: 0.9674 average iou: 0.5519 average dice: 0.6875 \n",
      "----------\n",
      "Epoch 2/50\n",
      "1/298, train_loss: 0.4713 iou: 0.6314 dice: 0.7737\n",
      "11/298, train_loss: 0.1585 iou: 0.8508 dice: 0.9191\n",
      "21/298, train_loss: 1.3844 iou: 0.7263 dice: 0.8412\n",
      "31/298, train_loss: 0.5125 iou: 0.6609 dice: 0.7947\n",
      "41/298, train_loss: 0.3826 iou: 0.8410 dice: 0.9135\n",
      "51/298, train_loss: 0.3081 iou: 0.4420 dice: 0.6120\n",
      "61/298, train_loss: 0.1993 iou: 0.8336 dice: 0.9088\n",
      "81/298, train_loss: 0.3547 iou: 0.6049 dice: 0.7484\n",
      "91/298, train_loss: 0.2466 iou: 0.6741 dice: 0.8047\n",
      "111/298, train_loss: 0.3518 iou: 0.6320 dice: 0.7716\n",
      "121/298, train_loss: 0.7784 iou: 0.8211 dice: 0.9014\n",
      "131/298, train_loss: 0.6723 iou: 0.7017 dice: 0.8229\n",
      "141/298, train_loss: 0.2645 iou: 0.7151 dice: 0.8322\n",
      "151/298, train_loss: 0.5790 iou: 0.6798 dice: 0.8086\n",
      "161/298, train_loss: 0.2332 iou: 0.7471 dice: 0.8547\n",
      "171/298, train_loss: 0.3265 iou: 0.7717 dice: 0.8705\n",
      "181/298, train_loss: 0.3244 iou: 0.7762 dice: 0.8735\n",
      "191/298, train_loss: 0.5774 iou: 0.6788 dice: 0.8042\n",
      "201/298, train_loss: 0.1275 iou: 0.6582 dice: 0.7878\n",
      "211/298, train_loss: 0.2121 iou: 0.8236 dice: 0.9029\n",
      "221/298, train_loss: 0.3295 iou: 0.7707 dice: 0.8698\n",
      "231/298, train_loss: 0.2385 iou: 0.7204 dice: 0.8363\n",
      "241/298, train_loss: 0.2986 iou: 0.6741 dice: 0.8034\n",
      "251/298, train_loss: 0.4057 iou: 0.7407 dice: 0.8499\n",
      "261/298, train_loss: 0.1845 iou: 0.7227 dice: 0.8383\n",
      "271/298, train_loss: 0.2041 iou: 0.7467 dice: 0.8547\n",
      "291/298, train_loss: 0.1661 iou: 0.8264 dice: 0.9046\n",
      "epoch 2 average loss: 0.3450 average iou: 0.7212 average dice: 0.8335 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data.local/phinv/envs/echo/lib/python3.7/site-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "current epoch 2 current mean dice: 0.7707174440230471 best mean iou: 0.7427061383540814 at epoch 2\n",
      "----------\n",
      "Epoch 3/50\n",
      "1/298, train_loss: 0.2182 iou: 0.7561 dice: 0.8609\n",
      "11/298, train_loss: 0.1565 iou: 0.8531 dice: 0.9206\n",
      "21/298, train_loss: 0.2219 iou: 0.7596 dice: 0.8604\n",
      "31/298, train_loss: 0.5491 iou: 0.6393 dice: 0.7797\n",
      "41/298, train_loss: 0.2580 iou: 0.7160 dice: 0.8341\n",
      "51/298, train_loss: 0.6191 iou: 0.6599 dice: 0.7948\n",
      "61/298, train_loss: 0.4287 iou: 0.7094 dice: 0.8296\n",
      "71/298, train_loss: 0.1404 iou: 0.8776 dice: 0.9344\n",
      "81/298, train_loss: 0.1347 iou: 0.5947 dice: 0.7388\n",
      "91/298, train_loss: 0.3132 iou: 0.7532 dice: 0.8576\n",
      "101/298, train_loss: 0.2762 iou: 0.8763 dice: 0.9339\n",
      "111/298, train_loss: 0.2487 iou: 0.8335 dice: 0.9090\n",
      "121/298, train_loss: 0.2984 iou: 0.7689 dice: 0.8678\n",
      "131/298, train_loss: 0.3111 iou: 0.7732 dice: 0.8716\n",
      "141/298, train_loss: 0.2448 iou: 0.7933 dice: 0.8845\n",
      "151/298, train_loss: 0.2552 iou: 0.7859 dice: 0.8797\n",
      "161/298, train_loss: 0.3838 iou: 0.6904 dice: 0.8160\n",
      "171/298, train_loss: 0.5152 iou: 0.7316 dice: 0.8447\n",
      "181/298, train_loss: 0.5718 iou: 0.8088 dice: 0.8940\n",
      "191/298, train_loss: 0.3886 iou: 0.7689 dice: 0.8691\n",
      "201/298, train_loss: 0.1705 iou: 0.7680 dice: 0.8672\n",
      "211/298, train_loss: 0.1336 iou: 0.7630 dice: 0.8635\n",
      "221/298, train_loss: 0.2312 iou: 0.6597 dice: 0.7938\n",
      "231/298, train_loss: 0.1462 iou: 0.8860 dice: 0.9395\n",
      "241/298, train_loss: 0.1189 iou: 0.7807 dice: 0.8762\n",
      "251/298, train_loss: 0.1865 iou: 0.8369 dice: 0.9110\n",
      "261/298, train_loss: 0.3103 iou: 0.7336 dice: 0.8439\n",
      "271/298, train_loss: 0.2207 iou: 0.8058 dice: 0.8917\n",
      "281/298, train_loss: 0.2592 iou: 0.6867 dice: 0.8091\n",
      "291/298, train_loss: 0.2016 iou: 0.7306 dice: 0.8399\n",
      "epoch 3 average loss: 0.3071 average iou: 0.7600 average dice: 0.8606 \n",
      "----------\n",
      "Epoch 4/50\n",
      "1/298, train_loss: 0.3411 iou: 0.5240 dice: 0.6862\n",
      "11/298, train_loss: 0.3842 iou: 0.7018 dice: 0.8169\n",
      "21/298, train_loss: 0.2202 iou: 0.7531 dice: 0.8588\n",
      "31/298, train_loss: 0.6762 iou: 0.6873 dice: 0.8143\n",
      "41/298, train_loss: 0.4953 iou: 0.7343 dice: 0.8461\n",
      "51/298, train_loss: 2.0648 iou: 0.4564 dice: 0.6261\n",
      "61/298, train_loss: 0.2798 iou: 0.7598 dice: 0.8629\n",
      "71/298, train_loss: 0.1678 iou: 0.6896 dice: 0.8150\n",
      "91/298, train_loss: 0.6319 iou: 0.7063 dice: 0.8274\n",
      "101/298, train_loss: 0.1282 iou: 0.8053 dice: 0.8916\n",
      "111/298, train_loss: 0.1161 iou: 0.8194 dice: 0.9006\n",
      "121/298, train_loss: 0.3105 iou: 0.7876 dice: 0.8803\n",
      "131/298, train_loss: 1.1352 iou: 0.7247 dice: 0.8400\n",
      "141/298, train_loss: 0.2519 iou: 0.7705 dice: 0.8700\n",
      "151/298, train_loss: 0.2097 iou: 0.7118 dice: 0.8310\n",
      "161/298, train_loss: 0.2069 iou: 0.8142 dice: 0.8973\n",
      "171/298, train_loss: 0.3928 iou: 0.8236 dice: 0.9026\n",
      "181/298, train_loss: 0.4313 iou: 0.7330 dice: 0.8393\n",
      "191/298, train_loss: 0.1655 iou: 0.5281 dice: 0.6781\n",
      "201/298, train_loss: 0.2022 iou: 0.7810 dice: 0.8766\n",
      "211/298, train_loss: 0.0856 iou: 0.8212 dice: 0.9018\n",
      "221/298, train_loss: 0.2802 iou: 0.7785 dice: 0.8749\n",
      "231/298, train_loss: 0.3552 iou: 0.7930 dice: 0.8840\n",
      "251/298, train_loss: 0.3305 iou: 0.8112 dice: 0.8952\n",
      "261/298, train_loss: 0.6799 iou: 0.6944 dice: 0.8190\n",
      "271/298, train_loss: 0.3584 iou: 0.8168 dice: 0.8989\n",
      "281/298, train_loss: 0.2627 iou: 0.8367 dice: 0.9109\n",
      "291/298, train_loss: 0.3167 iou: 0.6021 dice: 0.7494\n",
      "epoch 4 average loss: 0.3109 average iou: 0.7309 average dice: 0.8391 \n",
      "saved new best metric model\n",
      "current epoch 4 current mean dice: 0.7650516145724291 best mean iou: 0.7591171310498164 at epoch 4\n",
      "----------\n",
      "Epoch 5/50\n",
      "1/298, train_loss: 0.0870 iou: 0.8830 dice: 0.9378\n",
      "11/298, train_loss: 0.2185 iou: 0.7784 dice: 0.8739\n",
      "21/298, train_loss: 0.3413 iou: 0.7570 dice: 0.8607\n",
      "31/298, train_loss: 0.0730 iou: 0.8849 dice: 0.9388\n",
      "51/298, train_loss: 0.2305 iou: 0.8438 dice: 0.9146\n",
      "61/298, train_loss: 0.1817 iou: 0.7930 dice: 0.8826\n",
      "71/298, train_loss: 1.0317 iou: 0.4257 dice: 0.5952\n",
      "81/298, train_loss: 0.3314 iou: 0.8178 dice: 0.8988\n",
      "91/298, train_loss: 0.4204 iou: 0.7927 dice: 0.8816\n",
      "101/298, train_loss: 0.1643 iou: 0.7493 dice: 0.8562\n",
      "121/298, train_loss: 0.3169 iou: 0.7911 dice: 0.8826\n",
      "131/298, train_loss: 0.1640 iou: 0.7423 dice: 0.8508\n",
      "151/298, train_loss: 0.1686 iou: 0.7984 dice: 0.8877\n",
      "161/298, train_loss: 0.3086 iou: 0.7502 dice: 0.8557\n",
      "171/298, train_loss: 0.3791 iou: 0.7169 dice: 0.8334\n",
      "181/298, train_loss: 0.1798 iou: 0.8553 dice: 0.9215\n",
      "191/298, train_loss: 0.2226 iou: 0.8620 dice: 0.9256\n",
      "201/298, train_loss: 0.2135 iou: 0.8641 dice: 0.9269\n",
      "211/298, train_loss: 0.1147 iou: 0.8329 dice: 0.9088\n",
      "221/298, train_loss: 0.1800 iou: 0.8291 dice: 0.9063\n",
      "231/298, train_loss: 0.1926 iou: 0.7156 dice: 0.8340\n",
      "241/298, train_loss: 0.1397 iou: 0.7404 dice: 0.8507\n",
      "251/298, train_loss: 0.1352 iou: 0.6357 dice: 0.7675\n",
      "261/298, train_loss: 0.2183 iou: 0.7688 dice: 0.8688\n",
      "271/298, train_loss: 0.1614 iou: 0.8021 dice: 0.8879\n",
      "281/298, train_loss: 0.0734 iou: 0.8753 dice: 0.9332\n",
      "291/298, train_loss: 0.1934 iou: 0.7823 dice: 0.8776\n",
      "epoch 5 average loss: 0.2646 average iou: 0.7810 average dice: 0.8726 \n",
      "----------\n",
      "Epoch 6/50\n",
      "1/298, train_loss: 0.2043 iou: 0.7273 dice: 0.8375\n",
      "11/298, train_loss: 0.0843 iou: 0.9001 dice: 0.9474\n",
      "21/298, train_loss: 0.1915 iou: 0.8031 dice: 0.8888\n",
      "41/298, train_loss: 0.1189 iou: 0.8489 dice: 0.9176\n",
      "51/298, train_loss: 0.1539 iou: 0.8810 dice: 0.9366\n",
      "61/298, train_loss: 0.1506 iou: 0.7994 dice: 0.8881\n",
      "71/298, train_loss: 0.1590 iou: 0.8809 dice: 0.9364\n",
      "81/298, train_loss: 0.1732 iou: 0.8427 dice: 0.9145\n",
      "91/298, train_loss: 0.3198 iou: 0.6366 dice: 0.7767\n",
      "101/298, train_loss: 0.1922 iou: 0.8506 dice: 0.9189\n",
      "111/298, train_loss: 0.3658 iou: 0.7506 dice: 0.8572\n",
      "121/298, train_loss: 0.3067 iou: 0.7934 dice: 0.8844\n",
      "131/298, train_loss: 0.2369 iou: 0.8405 dice: 0.9130\n",
      "141/298, train_loss: 0.2276 iou: 0.8124 dice: 0.8961\n",
      "151/298, train_loss: 0.2358 iou: 0.7466 dice: 0.8548\n",
      "161/298, train_loss: 0.1602 iou: 0.8226 dice: 0.9019\n",
      "171/298, train_loss: 0.1418 iou: 0.8312 dice: 0.9076\n",
      "181/298, train_loss: 0.2426 iou: 0.7624 dice: 0.8647\n",
      "191/298, train_loss: 0.1053 iou: 0.7125 dice: 0.8303\n",
      "201/298, train_loss: 0.0964 iou: 0.8865 dice: 0.9397\n",
      "211/298, train_loss: 0.2337 iou: 0.8580 dice: 0.9234\n",
      "231/298, train_loss: 1.1156 iou: 0.8011 dice: 0.8893\n",
      "241/298, train_loss: 0.2190 iou: 0.6564 dice: 0.7902\n",
      "251/298, train_loss: 0.2478 iou: 0.7164 dice: 0.8346\n",
      "261/298, train_loss: 0.5368 iou: 0.6894 dice: 0.8158\n",
      "271/298, train_loss: 0.3178 iou: 0.6520 dice: 0.7891\n",
      "281/298, train_loss: 0.2150 iou: 0.6797 dice: 0.8085\n",
      "291/298, train_loss: 0.4692 iou: 0.7018 dice: 0.8195\n",
      "epoch 6 average loss: 0.2550 average iou: 0.7816 average dice: 0.8744 \n",
      "saved new best metric model\n",
      "current epoch 6 current mean dice: 0.6349919463600068 best mean iou: 0.7672365307807922 at epoch 6\n",
      "----------\n",
      "Epoch 7/50\n",
      "1/298, train_loss: 0.2237 iou: 0.7119 dice: 0.8316\n",
      "11/298, train_loss: 0.2793 iou: 0.7995 dice: 0.8885\n",
      "21/298, train_loss: 0.5739 iou: 0.7759 dice: 0.8730\n",
      "31/298, train_loss: 0.3070 iou: 0.7932 dice: 0.8830\n",
      "41/298, train_loss: 0.1465 iou: 0.8354 dice: 0.9101\n",
      "51/298, train_loss: 0.2155 iou: 0.7511 dice: 0.8571\n",
      "61/298, train_loss: 0.5111 iou: 0.8383 dice: 0.9120\n",
      "81/298, train_loss: 0.3320 iou: 0.7949 dice: 0.8850\n",
      "91/298, train_loss: 0.3293 iou: 0.7971 dice: 0.8865\n",
      "101/298, train_loss: 0.1334 iou: 0.7760 dice: 0.8728\n",
      "111/298, train_loss: 0.1465 iou: 0.7858 dice: 0.8796\n",
      "121/298, train_loss: 0.1621 iou: 0.7194 dice: 0.8361\n",
      "131/298, train_loss: 0.2870 iou: 0.7426 dice: 0.8514\n"
     ]
    }
   ],
   "source": [
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "total_step = len(train_ds) // train_loader.batch_size\n",
    "num_epoch = 50\n",
    "for epoch in range(num_epoch):\n",
    "    print('-' * 10)\n",
    "    print('Epoch {}/{}'.format(epoch + 1, num_epoch))\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_dice = 0\n",
    "    epoch_iou = 0\n",
    "    step = 0\n",
    "    num_log_step = 0\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        step += 1\n",
    "        inputs, labels, is_masks = batch_data['image'].to(device), batch_data['label'].to(device), batch_data['correct_masks'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = [torch.nn.functional.softmax(output) for output in outputs]\n",
    "        loss = loss_function(outputs[0], labels, is_masks)\\\n",
    "             + loss_function(outputs[1], labels, is_masks)\\\n",
    "             + loss_function(outputs[2], labels, is_masks)\\\n",
    "             + loss_function(outputs[3], labels, is_masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        if batch_idx % 10 ==0:\n",
    "            if torch.sum(is_masks) !=0:\n",
    "                iou, dice = segmentation_metrics(outputs[-1],labels,is_masks)\n",
    "                if not np.isnan(iou) and not np.isnan(dice):\n",
    "                    epoch_dice += dice\n",
    "                    epoch_iou += iou\n",
    "                    num_log_step += 1\n",
    "                print('{}/{}, train_loss: {:.4f} iou: {:.4f} dice: {:.4f}'.format(step, total_step , loss.item(),iou,dice))\n",
    "    epoch_loss /= step\n",
    "    epoch_dice /= num_log_step\n",
    "    epoch_iou /= num_log_step\n",
    "    \n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print('epoch {} average loss: {:.4f} average iou: {:.4f} average dice: {:.4f} '.format(epoch + 1, epoch_loss,epoch_iou,epoch_dice))\n",
    "   \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        dices = []\n",
    "        ious = []\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels, is_masks = val_data['image'].to(device), val_data['label'].to(device), val_data['correct_masks'].to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_outputs = torch.nn.functional.softmax(val_outputs)\n",
    "                if torch.sum(is_masks) !=0:\n",
    "                    iou, dice = segmentation_metrics(val_outputs,val_labels,is_masks)\n",
    "                    ious.append(iou)\n",
    "                    dices.append(dice)\n",
    "        metric = np.mean(iou)\n",
    "        metric_values.append(metric)\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), 'best_metric_model.pth')\n",
    "            print('saved new best metric model')\n",
    "        print(f'current epoch {epoch + 1} current mean dice: {np.mean(dices)} best mean iou: {best_metric} at epoch {best_metric_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "def write_mask(frame,pred,mask = None):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "    if mask is not None:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        mask[..., 1] = 0\n",
    "        mask[..., 2] = 0\n",
    "        frame = cv2.addWeighted(frame, 0.75, mask, 0.25, 0)\n",
    "    \n",
    "    pred = cv2.cvtColor(pred, cv2.COLOR_GRAY2BGR)\n",
    "    pred[..., 0] = 0\n",
    "    pred[..., 1] = 0\n",
    "    frame = cv2.addWeighted(frame, 0.75, pred, 0.25, 0)\n",
    "    return frame\n",
    "# device = 'cpu'\n",
    "# model.load_state_dict(torch.load('./best_metric_model.pth'))\n",
    "# model.to(device)\n",
    "for select_set in ['train']:\n",
    "    \n",
    "    if select_set == 'val':\n",
    "        dataset = val_ds\n",
    "    else:\n",
    "        dataset = train_ds\n",
    "    model.eval()\n",
    "    for batch_idx,batch_data in enumerate(dataset):\n",
    "        inputs, labels, is_masks = batch_data['image'].to(device), batch_data['label'].to(device), batch_data['correct_masks'].to(device)\n",
    "        outputs = model(inputs[None,...])\n",
    "        outputs = torch.nn.functional.softmax(outputs)[0]\n",
    "        if torch.sum(is_masks) !=0:\n",
    "            iou, dice = segmentation_metrics(outputs[None,...],labels[None,...],is_masks[None,...])\n",
    "            if iou > 1 or dice >1:\n",
    "                break\n",
    "\n",
    "        viz_frames = []\n",
    "        viz_preds = torch.argmax(outputs,dim=0)\n",
    "        viz_preds = viz_preds.cpu().detach().numpy()\n",
    "        images = inputs[0].cpu().detach().numpy()\n",
    "        masks = labels[1].cpu().detach().numpy()\n",
    "        \n",
    "        C,T,H,W = inputs.shape\n",
    "        for frame_idx in range(T):\n",
    "            viz_frame = np.uint8(images[frame_idx])\n",
    "            viz_pred = np.uint8(viz_preds[frame_idx]*255)\n",
    "            viz_mask = np.uint8(masks[frame_idx]*255)\n",
    "            viz_frame = write_mask(viz_frame,viz_pred,viz_mask)\n",
    "            viz_frames.append(viz_frame)\n",
    "        gif_path = f'./outs_dev/{select_set}_{iou}.gif'\n",
    "        print(f\"{batch_idx}_{iou}\")\n",
    "        with imageio.get_writer(gif_path, mode='I', fps=10) as gif_writer:\n",
    "            for frame in viz_frames:\n",
    "                gif_writer.append_data(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'current epoch {epoch + 1} current mean dice: {np.mean(dices)} best mean iou: {best_metric} at epoch {best_metric_epoch}')\n",
    "# def segmentation_metrics(ypred, ytrue,is_masks):\n",
    "#     eps = 1e-6\n",
    "#     num_frame = ypred.shape[-1]\n",
    "#     ypred = torch.argmax(ypred,dim=1).view(-1,num_frame)\n",
    "#     ytrue = torch.argmax(ytrue,dim=1).view(-1,num_frame)\n",
    "#     is_masks = is_masks[0]\n",
    "#     with torch.no_grad():\n",
    "#         intersection = torch.sum(ypred*ytrue,dim=0)\n",
    "#         union = torch.sum(ypred,dim=0)+torch.sum(ytrue,dim=0)\n",
    "#         iou = (intersection+eps)/(union-intersection+eps)\n",
    "#         dice = (2*intersection+eps)/(union+eps)\n",
    "#         iou = torch.mean(iou[is_masks]).item()\n",
    "#         dice = torch.mean(dice[is_masks]).item()\n",
    "        \n",
    "#         return iou, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'current epoch {epoch + 1} current mean dice: {np.mean(dices)} best mean iou: {best_metric} at epoch {best_metric_epoch}')\n",
    "# def segmentation_metrics(ypred, ytrue,is_masks):\n",
    "#     eps = 1e-6\n",
    "#     num_frame = ypred.shape[-1]\n",
    "#     ypred = torch.argmax(ypred,dim=1).view(-1,num_frame)\n",
    "#     ytrue = torch.argmax(ytrue,dim=1).view(-1,num_frame)\n",
    "#     is_masks = is_masks[0]\n",
    "#     with torch.no_grad():\n",
    "#         intersection = torch.sum(ypred*ytrue,dim=0)\n",
    "#         union = torch.sum(ypred,dim=0)+torch.sum(ytrue,dim=0)\n",
    "#         iou = (intersection+eps)/(union-intersection+eps)\n",
    "#         dice = (2*intersection+eps)/(union+eps)\n",
    "#         iou = torch.mean(iou[is_masks]).item()\n",
    "#         dice = torch.mean(dice[is_masks]).item()\n",
    "        \n",
    "#         return iou, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data['image'][None,...]\n",
    "y_true = data['label'][None,...]\n",
    "is_masks = data['correct_masks'][None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(inputs.to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softIoU(y_pred, y_true, is_masks):\n",
    "    y_pred = y_pred.contiguous()\n",
    "    y_true = y_true.contiguous()\n",
    "    B,C,T,H,W = y_pred.shape\n",
    "    y_pred = y_pred.view(B,T,-1)\n",
    "    y_true = y_true.view(B,T,-1)\n",
    "    intersection = (y_true * y_pred).sum(dim=-1)\n",
    "    union = y_true.sum(dim=-1) + y_pred.sum(dim=-1) - intersection\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    loss = 1.0 - iou\n",
    "    print(loss.shape)\n",
    "    loss = loss[is_masks]\n",
    "    print(loss.shape)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def segmentation_metrics(ypreds, ytrues,is_masks):\n",
    "    eps = 1e-6\n",
    "    ypreds = ypreds.contiguous()\n",
    "    ytrues = ytrues.contiguous()\n",
    "    B,C,T,H,W = ytrues.shape\n",
    "    ypreds = torch.argmax(ypreds,dim=1)\n",
    "    ytrues = torch.argmax(ytrues,dim=1)\n",
    "    print(ypreds.shape)\n",
    "    is_masks = is_masks[0]\n",
    "    ious = []\n",
    "    dices = []\n",
    "    for i in range(T):\n",
    "        if is_masks[i]:\n",
    "            ypred = ypreds[:,i]\n",
    "            ytrue = ytrues[:,i]\n",
    "            with torch.no_grad():\n",
    "                intersection = torch.sum(ypred*ytrue)\n",
    "                union = torch.sum(ypred)+torch.sum(ytrue)\n",
    "                iou = (intersection+eps)/(union-intersection+eps)\n",
    "                dice = (2*intersection+eps)/(union+eps)\n",
    "                ious.append(iou.item())\n",
    "                dices.append(dice.item())\n",
    "        \n",
    "    return np.mean(ious), np.mean(dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segmentation_metrics(y_true[:,:,:4,...],y_true[:,:,:4,...],is_masks[:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_ = y_true.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_[:,:,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_masks[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchsummary.summary(model,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of params: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
